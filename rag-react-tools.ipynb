{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG - REACT - TOOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### FIRST 10 docs ############\n",
      "\n",
      "\n",
      "page_content='PUSH POSSIBLETM\\n\\nWAREHOUSE MANAGEMENT AND TRANSPORT EXECUTION FOR IBM i\\n\\nRELEASE NOTES 2024\\n\\n0' metadata={'source': 'mydata/WMI-RN.pdf'}\n",
      "\n",
      "\n",
      "page_content='0\\n\\nWMi AND TEi RELEASE NOTES\\n\\nCopyright and Disclaimer' metadata={'source': 'mydata/WMI-RN.pdf'}\n",
      "\n",
      "\n",
      "page_content='Copyright © 2024 Manhattan Associates, Inc. All rights reserved.' metadata={'source': 'mydata/WMI-RN.pdf'}\n",
      "\n",
      "\n",
      "page_content='This documentation, as well as the software described in it, is furnished under license and may be' metadata={'source': 'mydata/WMI-RN.pdf'}\n",
      "\n",
      "\n",
      "page_content='license and may be used or copied only in accordance with the terms of such license. The' metadata={'source': 'mydata/WMI-RN.pdf'}\n",
      "\n",
      "\n",
      "page_content='such license. The information in this documentation is furnished for informational use only, is' metadata={'source': 'mydata/WMI-RN.pdf'}\n",
      "\n",
      "\n",
      "page_content='use only, is subject to change without notice, and should not be construed as a commitment by' metadata={'source': 'mydata/WMI-RN.pdf'}\n",
      "\n",
      "\n",
      "page_content='as a commitment by Manhattan Associates, Inc. (“Manhattan”). No third-party patent liability is' metadata={'source': 'mydata/WMI-RN.pdf'}\n",
      "\n",
      "\n",
      "page_content='patent liability is assumed with respect to the use of the information contained herein. While' metadata={'source': 'mydata/WMI-RN.pdf'}\n",
      "\n",
      "\n",
      "page_content='herein. While every precaution has been taken in the preparation of this documentation, Manhattan' metadata={'source': 'mydata/WMI-RN.pdf'}\n",
      "####### LAST 10 docs ############\n",
      "\n",
      "\n",
      "page_content='Copyright © 2024 Manhattan Associates, Inc.\\n\\nPage 112' metadata={'source': 'mydata/Manhattan Active Supply Chain.pdf'}\n",
      "\n",
      "\n",
      "page_content='the strategy to criteria.' metadata={'source': 'mydata/Manhattan Active Supply Chain.pdf'}\n",
      "\n",
      "\n",
      "page_content='The ASN Service Assignment Strategy needs to be conﬁgured prior to assigning the strategy to' metadata={'source': 'mydata/Manhattan Active Supply Chain.pdf'}\n",
      "\n",
      "\n",
      "page_content='Either blank or any pre-configured ASN Service Assignment Strategy' metadata={'source': 'mydata/Manhattan Active Supply Chain.pdf'}\n",
      "\n",
      "\n",
      "page_content='Possible Values/Description\\n\\nDependency\\n\\nASN Service Assignment Strategy' metadata={'source': 'mydata/Manhattan Active Supply Chain.pdf'}\n",
      "\n",
      "\n",
      "page_content='LPN and Item business objects.\\n\\nASN Planning Criteria Attributes Attribute Name' metadata={'source': 'mydata/Manhattan Active Supply Chain.pdf'}\n",
      "\n",
      "\n",
      "page_content='Strategy to a criteria. The rules are based on attributes related to ASN, ASN Line,' metadata={'source': 'mydata/Manhattan Active Supply Chain.pdf'}\n",
      "\n",
      "\n",
      "page_content='ASN Planning Criteria Rules ASN planning criteria rules link the ASN Planning Strategy to a' metadata={'source': 'mydata/Manhattan Active Supply Chain.pdf'}\n",
      "\n",
      "\n",
      "page_content='functions.' metadata={'source': 'mydata/Manhattan Active Supply Chain.pdf'}\n",
      "\n",
      "\n",
      "page_content='for the different planning attributes which control the ASN-based planning' metadata={'source': 'mydata/Manhattan Active Supply Chain.pdf'}\n",
      "############## # of Documents ##################\n",
      "4340\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import hub\n",
    "from langchain.agents import Tool, AgentExecutor, initialize_agent, create_react_agent\n",
    "from langchain.tools import DuckDuckGoSearchRun, WikipediaQueryRun\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMMathChain, LLMChain\n",
    "\n",
    "# Create tools for the agent\n",
    "################### first custom tool #############\n",
    "\n",
    "#create the WMI serach tool\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "\n",
    "#Load the documents\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "#loader = TextLoader(\"./bella_vista.txt\")\n",
    "DATA_PATH = \"mydata\"\n",
    "loader = DirectoryLoader(DATA_PATH, glob=\"*.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "\n",
    "#Split the documents\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "documents = text_splitter.split_documents(docs)\n",
    "\n",
    "#for doc in documents:\n",
    "    #print(\"\\n\")\n",
    "    #print(doc)\n",
    "\n",
    "print(\"####### FIRST 10 docs ############\")\n",
    "for i in range(10):\n",
    "    print(\"\\n\")\n",
    "    print(documents[i])\n",
    "\n",
    "print(\"####### LAST 10 docs ############\")\n",
    "x = documents[::-1]\n",
    "i = 0\n",
    "while (i < 10):\n",
    "    print(\"\\n\")\n",
    "    print(x[i])\n",
    "    i+= 1\n",
    "\n",
    "print(\"############## # of Documents ##################\")\n",
    "print(len(documents))\n",
    "\n",
    "#Initiatlise the Embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "#Initialize FAISS vector store\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "#Save the data\n",
    "vectorstore.save_local(\"index\") # newer FAISS versions can not be serialized with pickle\n",
    "\n",
    "#Load the vectoestore in memory to be used later\n",
    "vectorstore = FAISS.load_local(\"index\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "from typing import Optional\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.callbacks.manager import AsyncCallbackManagerForToolRun, CallbackManagerForToolRun\n",
    "\n",
    "class WMSearchTool(BaseTool):\n",
    "    name = \"WM search\"\n",
    "    description = \"useful when you need to answer questions about WM product\"\n",
    "\n",
    "    def _run(self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        store = vectorstore.as_retriever()\n",
    "        docs = store.get_relevant_documents(query)\n",
    "        text_list = [doc.page_content for doc in docs]\n",
    "        return \"\\n\".join(text_list)\n",
    "\n",
    "    async def _arun(self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"custom_search does not support async\")\n",
    "\n",
    "################## custom tool end ####################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "llm=OpenAI()\n",
    "\n",
    "# 1. Python REPL Tool (for executing Python code)\n",
    "python_repl = PythonREPLTool()\n",
    "python_repl_tool = Tool(\n",
    "    name='Python REPL',\n",
    "    func=python_repl.run,\n",
    "    description='Useful when you need to use Python to answer a question. You should input Python code.'\n",
    ")\n",
    "\n",
    "# 2. Wikipedia Tool (for searching Wikipedia)\n",
    "api_wrapper = WikipediaAPIWrapper()\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "wikipedia_tool = Tool(\n",
    "    name='Wikipedia',\n",
    "    func=wikipedia.run,\n",
    "    description='Useful for when you need to look up a topic, country, or person on Wikipedia.'\n",
    ")\n",
    "\n",
    "# 3. DuckDuckGo Search Tool (for general web searches)\n",
    "search = DuckDuckGoSearchRun()\n",
    "duckduckgo_tool = Tool(\n",
    "    name='DuckDuckGo Search',\n",
    "    func=search.run,\n",
    "    description='Useful for when you need to perform an internet search to find information that another tool can\\'t provide.'\n",
    ")\n",
    "\n",
    "#Another math tool as REPL not working as expected\n",
    "problem_chain = LLMMathChain.from_llm(llm=llm)\n",
    "math_tool = Tool.from_function(name=\"Calculator\",\n",
    "                func=problem_chain.run,\n",
    "                description=\"Useful for when you need to answer questions about math. This tool is only for math questions and nothing else. Only input math expressions.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Memory\n",
    "from langchain.memory import ConversationBufferMemory, FileChatMessageHistory\n",
    "history = FileChatMessageHistory('chat_history.json')\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history',\n",
    "    chat_memory=history,\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the ChatOpenAI model (gpt-4-turbo-preview) with a temperature of 0. Utilize gpt-3.5-turbo if you use the free plan\n",
    "llm = ChatOpenAI(model_name='gpt-4-turbo-preview', temperature=0)\n",
    "#llm=OpenAI()\n",
    "\n",
    "#Answer the following questions in GERMAN as best you can.\n",
    "# Define a template for answering questions\n",
    "template = '''\n",
    "Answer the following questions as best you can.\n",
    "Questions: {q}\n",
    "'''\n",
    "# Create a PromptTemplate object from the template\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "# Pull the react prompt from the hub\n",
    "prompt = hub.pull('hwchase17/react')\n",
    "\n",
    "\n",
    "# Combine the tools into a list\n",
    "tools = [WMSearchTool(), math_tool, python_repl_tool, wikipedia_tool, duckduckgo_tool]\n",
    "\n",
    "# Create a react agent with the ChatOpenAI model, tools, and prompt\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "# Initialize the AgentExecutor\n",
    "agent_executor = AgentExecutor(\n",
    "    memory=memory,\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo find out if the feature \"Creation of Multiple Process Needs for an Item\" is enabled by default in Manhattan Active® Warehouse Management, I should look up the official documentation or any reliable source of information regarding the software's features and settings.\n",
      "\n",
      "Action: WM search\n",
      "\n",
      "Action Input: \"Creation of Multiple Process Needs for an Item\" in Manhattan Active Warehouse Management enabled by default\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_tool_end callback: TracerException(\"Found chain run at ID 82ef2f9a-53e1-4039-b22f-2697e7a1f05c, but expected {'tool'} run.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mCreation of Multiple Process Needs for an Item\n",
      "Creation of Multiple Process Needs for an Item\n",
      "The solution allows users to create multiple process needs for an item, allowing them to add more\n",
      "To achieve this functionality, enable the “Should the system allow multiple Process needs creation\u001b[0m\u001b[32;1m\u001b[1;3mThe information provided does not explicitly state whether the feature \"Creation of Multiple Process Needs for an Item\" is enabled by default in Manhattan Active® Warehouse Management. It mentions that to achieve this functionality, one needs to enable a specific setting, but it does not clarify if this setting is enabled by default.\n",
      "\n",
      "Final Answer: The documentation does not explicitly state whether the feature \"Creation of Multiple Process Needs for an Item\" is enabled by default in Manhattan Active® Warehouse Management. It suggests that a specific setting needs to be enabled to use this functionality, implying it may not be enabled by default.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThis question is too vague without context about what specific feature is being referred to. Without knowing the specific feature or the software/application it pertains to, it's impossible to provide an accurate answer.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mGiven the lack of context about the specific feature in question, it's impossible to proceed with an accurate answer. The question needs to specify which feature and in what software or application it is referring to in order to provide a meaningful response.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mGiven the lack of context about the specific feature in question, it's impossible to proceed with an accurate answer. The question needs to specify which feature and in what software or application it is referring to in order to provide a meaningful response.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mGiven the lack of context about the specific feature in question, it's impossible to proceed with an accurate answer. The question needs to specify which feature and in what software or application it is referring to in order to provide a meaningful response.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mGiven the lack of context about the specific feature in question, it's impossible to proceed with an accurate answer. The question needs to specify which feature and in what software or application it is referring to in order to provide a meaningful response.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mGiven the lack of context about the specific feature in question, it's impossible to proceed with an accurate answer. The question needs to specify which feature and in what software or application it is referring to in order to provide a meaningful response.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mGiven the lack of context about the specific feature in question, it's impossible to proceed with an accurate answer. The question needs to specify which feature and in what software or application it is referring to in order to provide a meaningful response.\n",
      "Final Answer: Without specific details about the feature and its associated software or application, it is not possible to determine whether it is enabled by default.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#question = 'Does WMi support json interfaces?'\n",
    "#question = 'Who is the current prime minister of the UK?'\n",
    "#question = 'what is the answer to 3 ** 3.9'\n",
    "#question = 'Tell me about Napoleon Bonaparte early life'\n",
    "#question = 'how to enable \"Putaway To Empty Non-Replenishable Dynamic Active Locations\" in Manhattan Active Supply Chain'\n",
    "#question = 'how to enable \"Putaway To Empty Non-Replenishable Dynamic Active Locations\" in Manhattan Active® Warehouse Management'\n",
    "#question = 'Is the feature \"Creation of Multiple Process Needs for an Item\" in Manhattan Active Supply Chain, enabled by default?'\n",
    "question = 'Is the feature \"Creation of Multiple Process Needs for an Item\" in Manhattan Active® Warehouse Management, enabled by default?'\n",
    "\n",
    "output = agent_executor.invoke({\n",
    "    'input': prompt_template.format(q=question)\n",
    "})\n",
    "\n",
    "question = 'Is the feature enabled by default?'\n",
    "output = agent_executor.invoke({\n",
    "    'input': prompt_template.format(q=question)\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
